{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test Moggio RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1G1XQ0AF3Op-XuV9ZPCqSfsfxxBliytIq",
      "authorship_tag": "ABX9TyPLPPnDhnRWcxdB40oTW8sU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "50h6XyhAz59c"
      },
      "source": [
        "from math import sqrt\n",
        "from numpy import concatenate\n",
        "from matplotlib import pyplot\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA2CKbjH0LRW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "dabb416c-4b0b-43ed-f87f-896fa3fff1f1"
      },
      "source": [
        "table = read_csv('/content/drive/MyDrive/Thesis/csvs/NNdata.csv')\n",
        "table.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>IDStation</th>\n",
              "      <th>NameStation</th>\n",
              "      <th>Ammonia</th>\n",
              "      <th>Arsenic</th>\n",
              "      <th>Benzene</th>\n",
              "      <th>Benzo_a_pyrene</th>\n",
              "      <th>Cadmium</th>\n",
              "      <th>CO</th>\n",
              "      <th>Lead</th>\n",
              "      <th>Nikel</th>\n",
              "      <th>NO</th>\n",
              "      <th>NO2</th>\n",
              "      <th>NOx</th>\n",
              "      <th>Ozone</th>\n",
              "      <th>PM10</th>\n",
              "      <th>PM25</th>\n",
              "      <th>Sulfur_dioxide</th>\n",
              "      <th>IDStation.1</th>\n",
              "      <th>reg_Y_nn1_ID</th>\n",
              "      <th>Date.1</th>\n",
              "      <th>IDStation.2</th>\n",
              "      <th>NameStation.1</th>\n",
              "      <th>Wind_speed</th>\n",
              "      <th>Wind_direction</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Relative_humidity</th>\n",
              "      <th>Global_radiation</th>\n",
              "      <th>Wind_speed_max</th>\n",
              "      <th>Wind_direction_max</th>\n",
              "      <th>Rainfall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-01T00:00:00Z</td>\n",
              "      <td>677</td>\n",
              "      <td>Cremona Via Fatebenefratelli</td>\n",
              "      <td>6.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.508333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.175000</td>\n",
              "      <td>63.570833</td>\n",
              "      <td>5.225000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.0</td>\n",
              "      <td>1.829167</td>\n",
              "      <td>677</td>\n",
              "      <td>677</td>\n",
              "      <td>2018-01-01T00:00:00Z</td>\n",
              "      <td>677</td>\n",
              "      <td>Cremona Via Fatebenefratelli</td>\n",
              "      <td>0.483454</td>\n",
              "      <td>314.0</td>\n",
              "      <td>2.615278</td>\n",
              "      <td>93.738194</td>\n",
              "      <td>21.268056</td>\n",
              "      <td>2.133333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-01T00:00:00Z</td>\n",
              "      <td>681</td>\n",
              "      <td>Moggio</td>\n",
              "      <td>1.4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>3.308333</td>\n",
              "      <td>5.075000</td>\n",
              "      <td>66.100000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>681</td>\n",
              "      <td>111</td>\n",
              "      <td>2018-01-01T00:00:00Z</td>\n",
              "      <td>111</td>\n",
              "      <td>Cassina Valsassina Moggio</td>\n",
              "      <td>0.300970</td>\n",
              "      <td>65.0</td>\n",
              "      <td>2.095833</td>\n",
              "      <td>74.055556</td>\n",
              "      <td>60.152778</td>\n",
              "      <td>1.939583</td>\n",
              "      <td>144.0</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-01T00:00:00Z</td>\n",
              "      <td>703</td>\n",
              "      <td>Schivenoglia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.159091</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.572727</td>\n",
              "      <td>35.850000</td>\n",
              "      <td>9.281818</td>\n",
              "      <td>44.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>4.813636</td>\n",
              "      <td>703</td>\n",
              "      <td>671</td>\n",
              "      <td>2018-01-01T00:00:00Z</td>\n",
              "      <td>671</td>\n",
              "      <td>Mantova Tridolino</td>\n",
              "      <td>1.540787</td>\n",
              "      <td>288.0</td>\n",
              "      <td>2.761806</td>\n",
              "      <td>99.475694</td>\n",
              "      <td>14.163194</td>\n",
              "      <td>3.524306</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-02T00:00:00Z</td>\n",
              "      <td>677</td>\n",
              "      <td>Cremona Via Fatebenefratelli</td>\n",
              "      <td>1.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.925000</td>\n",
              "      <td>47.750000</td>\n",
              "      <td>18.441667</td>\n",
              "      <td>32.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.341667</td>\n",
              "      <td>677</td>\n",
              "      <td>677</td>\n",
              "      <td>2018-01-02T00:00:00Z</td>\n",
              "      <td>677</td>\n",
              "      <td>Cremona Via Fatebenefratelli</td>\n",
              "      <td>1.788399</td>\n",
              "      <td>284.0</td>\n",
              "      <td>5.974306</td>\n",
              "      <td>70.609722</td>\n",
              "      <td>72.734028</td>\n",
              "      <td>4.377083</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-02T00:00:00Z</td>\n",
              "      <td>681</td>\n",
              "      <td>Moggio</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.441667</td>\n",
              "      <td>1.283333</td>\n",
              "      <td>85.891667</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>681</td>\n",
              "      <td>111</td>\n",
              "      <td>2018-01-02T00:00:00Z</td>\n",
              "      <td>111</td>\n",
              "      <td>Cassina Valsassina Moggio</td>\n",
              "      <td>0.613183</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.670139</td>\n",
              "      <td>39.194444</td>\n",
              "      <td>68.250000</td>\n",
              "      <td>3.075000</td>\n",
              "      <td>213.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Date  IDStation  ... Wind_direction_max  Rainfall\n",
              "0  2018-01-01T00:00:00Z        677  ...                NaN       7.2\n",
              "1  2018-01-01T00:00:00Z        681  ...              144.0       2.4\n",
              "2  2018-01-01T00:00:00Z        703  ...                NaN       5.8\n",
              "3  2018-01-02T00:00:00Z        677  ...                NaN       0.0\n",
              "4  2018-01-02T00:00:00Z        681  ...              213.0       0.0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApNM1Dpm0ai-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0f959fc4-c675-4df6-be3c-8efeae9bfd3d"
      },
      "source": [
        "Moggio = table.loc[table.loc[:,\"NameStation\"]==\"Moggio\",:]\n",
        "Moggio = Moggio.loc[:,[\"Date\",\"Ammonia\",\"PM10\",\"PM25\",\"Wind_speed\",\"Wind_direction\",\"Temperature\",\"Rainfall\"]]\n",
        "Moggio = Moggio.dropna(how=\"any\")\n",
        "Moggio = Moggio.reset_index()\n",
        "Moggio = Moggio.iloc[:730,:] # we train not using 2020, for now\n",
        "Moggio.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Date</th>\n",
              "      <th>Ammonia</th>\n",
              "      <th>PM10</th>\n",
              "      <th>PM25</th>\n",
              "      <th>Wind_speed</th>\n",
              "      <th>Wind_direction</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Rainfall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2018-01-01T00:00:00Z</td>\n",
              "      <td>1.4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.300970</td>\n",
              "      <td>65.0</td>\n",
              "      <td>2.095833</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>2018-01-02T00:00:00Z</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.613183</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.670139</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>2018-01-03T00:00:00Z</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.539172</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.972222</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>2018-01-04T00:00:00Z</td>\n",
              "      <td>1.4</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.211450</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.081250</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>2018-01-05T00:00:00Z</td>\n",
              "      <td>1.7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.116953</td>\n",
              "      <td>87.0</td>\n",
              "      <td>3.653472</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                  Date  Ammonia  ...  Wind_direction  Temperature  Rainfall\n",
              "0      1  2018-01-01T00:00:00Z      1.4  ...            65.0     2.095833       2.4\n",
              "1      4  2018-01-02T00:00:00Z      1.0  ...             9.0     1.670139       0.0\n",
              "2      7  2018-01-03T00:00:00Z      1.0  ...            28.0     1.972222       0.6\n",
              "3     10  2018-01-04T00:00:00Z      1.4  ...            21.0     3.081250       0.0\n",
              "4     13  2018-01-05T00:00:00Z      1.7  ...            87.0     3.653472       0.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wXsLnh_1JbF"
      },
      "source": [
        "##Convert series to supervised learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24Av99KQ1UEW"
      },
      "source": [
        "###Conversion Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb-KlY4Q0amR"
      },
      "source": [
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        " \n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\t\"\"\"\n",
        "\tFrame a time series as a supervised learning dataset.\n",
        "\tArguments:\n",
        "\t\tdata: Sequence of observations as a list or NumPy array.\n",
        "\t\tn_in: Number of lag observations as input (X).\n",
        "\t\tn_out: Number of observations as output (y).\n",
        "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
        "\tReturns:\n",
        "\t\tPandas DataFrame of series framed for supervised learning.\n",
        "\t\"\"\"\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0zHE-3h1vGz"
      },
      "source": [
        "### Conversion of Moggio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwL5Zn9j11Ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "4240bcd5-0d56-4c22-e7c2-983dd837de78"
      },
      "source": [
        "values = Moggio.iloc[:,2:].values\n",
        "# ensure all data is float\n",
        "values = values.astype('float32')\n",
        "# normalize features\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(values)\n",
        "# frame as supervised learning\n",
        "n_days = 5\n",
        "reframed = series_to_supervised(scaled, n_days, 1) # info of the past 5 days to determine next (1) day\n",
        "# drop columns we don't want to predict (we therefore keep Ammonia)\n",
        "reframed.drop(reframed.columns[[36,37,38,39,40,41]], axis=1, inplace=True)\n",
        "\n",
        "reframed.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var1(t-5)</th>\n",
              "      <th>var2(t-5)</th>\n",
              "      <th>var3(t-5)</th>\n",
              "      <th>var4(t-5)</th>\n",
              "      <th>var5(t-5)</th>\n",
              "      <th>var6(t-5)</th>\n",
              "      <th>var7(t-5)</th>\n",
              "      <th>var1(t-4)</th>\n",
              "      <th>var2(t-4)</th>\n",
              "      <th>var3(t-4)</th>\n",
              "      <th>var4(t-4)</th>\n",
              "      <th>var5(t-4)</th>\n",
              "      <th>var6(t-4)</th>\n",
              "      <th>var7(t-4)</th>\n",
              "      <th>var1(t-3)</th>\n",
              "      <th>var2(t-3)</th>\n",
              "      <th>var3(t-3)</th>\n",
              "      <th>var4(t-3)</th>\n",
              "      <th>var5(t-3)</th>\n",
              "      <th>var6(t-3)</th>\n",
              "      <th>var7(t-3)</th>\n",
              "      <th>var1(t-2)</th>\n",
              "      <th>var2(t-2)</th>\n",
              "      <th>var3(t-2)</th>\n",
              "      <th>var4(t-2)</th>\n",
              "      <th>var5(t-2)</th>\n",
              "      <th>var6(t-2)</th>\n",
              "      <th>var7(t-2)</th>\n",
              "      <th>var1(t-1)</th>\n",
              "      <th>var2(t-1)</th>\n",
              "      <th>var3(t-1)</th>\n",
              "      <th>var4(t-1)</th>\n",
              "      <th>var5(t-1)</th>\n",
              "      <th>var6(t-1)</th>\n",
              "      <th>var7(t-1)</th>\n",
              "      <th>var1(t)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.069307</td>\n",
              "      <td>0.081967</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.107422</td>\n",
              "      <td>0.180556</td>\n",
              "      <td>0.349921</td>\n",
              "      <td>0.024540</td>\n",
              "      <td>0.049505</td>\n",
              "      <td>0.049180</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.224783</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.338791</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.049505</td>\n",
              "      <td>0.081967</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.196962</td>\n",
              "      <td>0.077778</td>\n",
              "      <td>0.346689</td>\n",
              "      <td>0.006135</td>\n",
              "      <td>0.069307</td>\n",
              "      <td>0.098361</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.073772</td>\n",
              "      <td>0.058333</td>\n",
              "      <td>0.375686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084158</td>\n",
              "      <td>0.114754</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>0.038250</td>\n",
              "      <td>0.241667</td>\n",
              "      <td>0.390648</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.094059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.049505</td>\n",
              "      <td>0.049180</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.224783</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.338791</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.049505</td>\n",
              "      <td>0.081967</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.196962</td>\n",
              "      <td>0.077778</td>\n",
              "      <td>0.346689</td>\n",
              "      <td>0.006135</td>\n",
              "      <td>0.069307</td>\n",
              "      <td>0.098361</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.073772</td>\n",
              "      <td>0.058333</td>\n",
              "      <td>0.375686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084158</td>\n",
              "      <td>0.114754</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>0.038250</td>\n",
              "      <td>0.241667</td>\n",
              "      <td>0.390648</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.094059</td>\n",
              "      <td>0.098361</td>\n",
              "      <td>0.155556</td>\n",
              "      <td>0.476069</td>\n",
              "      <td>0.361111</td>\n",
              "      <td>0.403358</td>\n",
              "      <td>0.100204</td>\n",
              "      <td>0.094059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.049505</td>\n",
              "      <td>0.081967</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.196962</td>\n",
              "      <td>0.077778</td>\n",
              "      <td>0.346689</td>\n",
              "      <td>0.006135</td>\n",
              "      <td>0.069307</td>\n",
              "      <td>0.098361</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.073772</td>\n",
              "      <td>0.058333</td>\n",
              "      <td>0.375686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084158</td>\n",
              "      <td>0.114754</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>0.038250</td>\n",
              "      <td>0.241667</td>\n",
              "      <td>0.390648</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.094059</td>\n",
              "      <td>0.098361</td>\n",
              "      <td>0.155556</td>\n",
              "      <td>0.476069</td>\n",
              "      <td>0.361111</td>\n",
              "      <td>0.403358</td>\n",
              "      <td>0.100204</td>\n",
              "      <td>0.094059</td>\n",
              "      <td>0.163934</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>0.765240</td>\n",
              "      <td>0.597222</td>\n",
              "      <td>0.433662</td>\n",
              "      <td>0.012270</td>\n",
              "      <td>0.084158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.069307</td>\n",
              "      <td>0.098361</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.073772</td>\n",
              "      <td>0.058333</td>\n",
              "      <td>0.375686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084158</td>\n",
              "      <td>0.114754</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>0.038250</td>\n",
              "      <td>0.241667</td>\n",
              "      <td>0.390648</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.094059</td>\n",
              "      <td>0.098361</td>\n",
              "      <td>0.155556</td>\n",
              "      <td>0.476069</td>\n",
              "      <td>0.361111</td>\n",
              "      <td>0.403358</td>\n",
              "      <td>0.100204</td>\n",
              "      <td>0.094059</td>\n",
              "      <td>0.163934</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>0.765240</td>\n",
              "      <td>0.597222</td>\n",
              "      <td>0.433662</td>\n",
              "      <td>0.012270</td>\n",
              "      <td>0.084158</td>\n",
              "      <td>0.180328</td>\n",
              "      <td>0.155556</td>\n",
              "      <td>0.927869</td>\n",
              "      <td>0.602778</td>\n",
              "      <td>0.459754</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.084158</td>\n",
              "      <td>0.114754</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>0.038250</td>\n",
              "      <td>0.241667</td>\n",
              "      <td>0.390648</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.094059</td>\n",
              "      <td>0.098361</td>\n",
              "      <td>0.155556</td>\n",
              "      <td>0.476069</td>\n",
              "      <td>0.361111</td>\n",
              "      <td>0.403358</td>\n",
              "      <td>0.100204</td>\n",
              "      <td>0.094059</td>\n",
              "      <td>0.163934</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>0.765240</td>\n",
              "      <td>0.597222</td>\n",
              "      <td>0.433662</td>\n",
              "      <td>0.012270</td>\n",
              "      <td>0.084158</td>\n",
              "      <td>0.180328</td>\n",
              "      <td>0.155556</td>\n",
              "      <td>0.927869</td>\n",
              "      <td>0.602778</td>\n",
              "      <td>0.459754</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084158</td>\n",
              "      <td>0.245902</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.596370</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.391011</td>\n",
              "      <td>0.329243</td>\n",
              "      <td>0.074257</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   var1(t-5)  var2(t-5)  var3(t-5)  ...  var6(t-1)  var7(t-1)   var1(t)\n",
              "5   0.069307   0.081967   0.088889  ...   0.390648   0.000000  0.094059\n",
              "6   0.049505   0.049180   0.044444  ...   0.403358   0.100204  0.094059\n",
              "7   0.049505   0.081967   0.111111  ...   0.433662   0.012270  0.084158\n",
              "8   0.069307   0.098361   0.066667  ...   0.459754   0.000000  0.084158\n",
              "9   0.084158   0.114754   0.177778  ...   0.391011   0.329243  0.074257\n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Mx9MPBARpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207e4566-191d-46f3-ba85-88b11c1074d0"
      },
      "source": [
        "# split into train and test sets\n",
        "values = reframed.values\n",
        "n_features = 7 # number of variables, including the one to be predicted\n",
        "n_train_days = 365 # we train using only the first year\n",
        "train = values[:n_train_days, :]\n",
        "test = values[n_train_days:, :] # we test using all successive years \n",
        "# split into input and outputs\n",
        "n_obs = n_days * n_features\n",
        "train_X, train_y = train[:, :n_obs], train[:, -1]\n",
        "test_X, test_y = test[:, :n_obs], test[:, -1]\n",
        "print(train_X.shape, len(train_X), train_y.shape)\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], n_days, n_features))\n",
        "test_X = test_X.reshape((test_X.shape[0], n_days, n_features))\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(365, 35) 365 (365,)\n",
            "(365, 5, 7) (365,) (360, 5, 7) (360,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKLpWbJH7Kmj"
      },
      "source": [
        "# Modeling and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggc63fyoD9MG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c4d7f39-ad17-4c25-dbdf-e390b7a9f6be"
      },
      "source": [
        "# design network\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(50, return_sequences=False))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mae', optimizer='adam')\n",
        "# fit network\n",
        "early_stopping = EarlyStopping(patience=10, restore_best_weights = True)\n",
        "history = model.fit(train_X, train_y, epochs=1000, batch_size=100, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=early_stopping)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "4/4 - 7s - loss: 0.2019 - val_loss: 0.1667 - 7s/epoch - 2s/step\n",
            "Epoch 2/1000\n",
            "4/4 - 0s - loss: 0.1487 - val_loss: 0.1484 - 84ms/epoch - 21ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 0s - loss: 0.1130 - val_loss: 0.1485 - 83ms/epoch - 21ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 0s - loss: 0.1089 - val_loss: 0.1462 - 83ms/epoch - 21ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 0s - loss: 0.1032 - val_loss: 0.1390 - 88ms/epoch - 22ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 0s - loss: 0.0999 - val_loss: 0.1351 - 90ms/epoch - 23ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 0s - loss: 0.1000 - val_loss: 0.1306 - 86ms/epoch - 22ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 0s - loss: 0.0969 - val_loss: 0.1246 - 85ms/epoch - 21ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 0s - loss: 0.0906 - val_loss: 0.1192 - 85ms/epoch - 21ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 0s - loss: 0.0857 - val_loss: 0.1135 - 84ms/epoch - 21ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 0s - loss: 0.0811 - val_loss: 0.1074 - 83ms/epoch - 21ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 0s - loss: 0.0786 - val_loss: 0.1015 - 80ms/epoch - 20ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 0s - loss: 0.0761 - val_loss: 0.0983 - 83ms/epoch - 21ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 0s - loss: 0.0742 - val_loss: 0.0945 - 92ms/epoch - 23ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 0s - loss: 0.0732 - val_loss: 0.0917 - 86ms/epoch - 22ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 0s - loss: 0.0741 - val_loss: 0.0925 - 75ms/epoch - 19ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 0s - loss: 0.0728 - val_loss: 0.0918 - 85ms/epoch - 21ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 0s - loss: 0.0719 - val_loss: 0.0914 - 87ms/epoch - 22ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 0s - loss: 0.0714 - val_loss: 0.0932 - 83ms/epoch - 21ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 0s - loss: 0.0707 - val_loss: 0.0922 - 84ms/epoch - 21ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 0s - loss: 0.0706 - val_loss: 0.0915 - 87ms/epoch - 22ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 0s - loss: 0.0702 - val_loss: 0.0913 - 82ms/epoch - 21ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 0s - loss: 0.0699 - val_loss: 0.0904 - 81ms/epoch - 20ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 0s - loss: 0.0698 - val_loss: 0.0896 - 84ms/epoch - 21ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 0s - loss: 0.0696 - val_loss: 0.0894 - 84ms/epoch - 21ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 0s - loss: 0.0694 - val_loss: 0.0890 - 90ms/epoch - 22ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 0s - loss: 0.0690 - val_loss: 0.0881 - 89ms/epoch - 22ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 0s - loss: 0.0688 - val_loss: 0.0877 - 88ms/epoch - 22ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 0s - loss: 0.0685 - val_loss: 0.0872 - 85ms/epoch - 21ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 0s - loss: 0.0682 - val_loss: 0.0869 - 88ms/epoch - 22ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 0s - loss: 0.0679 - val_loss: 0.0864 - 85ms/epoch - 21ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 0s - loss: 0.0676 - val_loss: 0.0861 - 86ms/epoch - 21ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 0s - loss: 0.0674 - val_loss: 0.0854 - 89ms/epoch - 22ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 0s - loss: 0.0671 - val_loss: 0.0853 - 92ms/epoch - 23ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 0s - loss: 0.0668 - val_loss: 0.0845 - 89ms/epoch - 22ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 0s - loss: 0.0665 - val_loss: 0.0843 - 85ms/epoch - 21ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 0s - loss: 0.0661 - val_loss: 0.0836 - 96ms/epoch - 24ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 0s - loss: 0.0659 - val_loss: 0.0833 - 89ms/epoch - 22ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 0s - loss: 0.0655 - val_loss: 0.0828 - 92ms/epoch - 23ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 0s - loss: 0.0653 - val_loss: 0.0825 - 89ms/epoch - 22ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 0s - loss: 0.0650 - val_loss: 0.0820 - 84ms/epoch - 21ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 0s - loss: 0.0646 - val_loss: 0.0817 - 84ms/epoch - 21ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 0s - loss: 0.0641 - val_loss: 0.0811 - 84ms/epoch - 21ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 0s - loss: 0.0639 - val_loss: 0.0812 - 80ms/epoch - 20ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 0s - loss: 0.0632 - val_loss: 0.0799 - 87ms/epoch - 22ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 0s - loss: 0.0631 - val_loss: 0.0803 - 83ms/epoch - 21ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 0s - loss: 0.0625 - val_loss: 0.0789 - 82ms/epoch - 20ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 0s - loss: 0.0623 - val_loss: 0.0789 - 82ms/epoch - 20ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 0s - loss: 0.0616 - val_loss: 0.0776 - 81ms/epoch - 20ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 0s - loss: 0.0614 - val_loss: 0.0781 - 77ms/epoch - 19ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 0s - loss: 0.0610 - val_loss: 0.0764 - 84ms/epoch - 21ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 0s - loss: 0.0604 - val_loss: 0.0761 - 84ms/epoch - 21ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 0s - loss: 0.0600 - val_loss: 0.0758 - 84ms/epoch - 21ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 0s - loss: 0.0595 - val_loss: 0.0749 - 80ms/epoch - 20ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 0s - loss: 0.0590 - val_loss: 0.0740 - 88ms/epoch - 22ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 0s - loss: 0.0586 - val_loss: 0.0736 - 81ms/epoch - 20ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 0s - loss: 0.0582 - val_loss: 0.0730 - 84ms/epoch - 21ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 0s - loss: 0.0576 - val_loss: 0.0720 - 89ms/epoch - 22ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 0s - loss: 0.0571 - val_loss: 0.0711 - 92ms/epoch - 23ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 0s - loss: 0.0567 - val_loss: 0.0710 - 87ms/epoch - 22ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 0s - loss: 0.0562 - val_loss: 0.0697 - 88ms/epoch - 22ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 0s - loss: 0.0555 - val_loss: 0.0693 - 85ms/epoch - 21ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 0s - loss: 0.0550 - val_loss: 0.0688 - 89ms/epoch - 22ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 0s - loss: 0.0547 - val_loss: 0.0685 - 86ms/epoch - 21ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 0s - loss: 0.0540 - val_loss: 0.0676 - 87ms/epoch - 22ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 0s - loss: 0.0536 - val_loss: 0.0675 - 87ms/epoch - 22ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 0s - loss: 0.0534 - val_loss: 0.0677 - 85ms/epoch - 21ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 0s - loss: 0.0529 - val_loss: 0.0672 - 92ms/epoch - 23ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 0s - loss: 0.0523 - val_loss: 0.0667 - 91ms/epoch - 23ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 0s - loss: 0.0522 - val_loss: 0.0699 - 85ms/epoch - 21ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 0s - loss: 0.0550 - val_loss: 0.0698 - 86ms/epoch - 21ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 0s - loss: 0.0555 - val_loss: 0.0714 - 84ms/epoch - 21ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 0s - loss: 0.0559 - val_loss: 0.0660 - 84ms/epoch - 21ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 0s - loss: 0.0516 - val_loss: 0.0689 - 81ms/epoch - 20ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 0s - loss: 0.0532 - val_loss: 0.0699 - 79ms/epoch - 20ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 0s - loss: 0.0532 - val_loss: 0.0677 - 80ms/epoch - 20ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 0s - loss: 0.0520 - val_loss: 0.0677 - 83ms/epoch - 21ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 0s - loss: 0.0517 - val_loss: 0.0679 - 84ms/epoch - 21ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 0s - loss: 0.0515 - val_loss: 0.0677 - 89ms/epoch - 22ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 0s - loss: 0.0515 - val_loss: 0.0668 - 76ms/epoch - 19ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 0s - loss: 0.0504 - val_loss: 0.0674 - 80ms/epoch - 20ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 0s - loss: 0.0498 - val_loss: 0.0662 - 83ms/epoch - 21ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 0s - loss: 0.0494 - val_loss: 0.0658 - 94ms/epoch - 23ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 0s - loss: 0.0491 - val_loss: 0.0659 - 80ms/epoch - 20ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 0s - loss: 0.0487 - val_loss: 0.0654 - 85ms/epoch - 21ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 0s - loss: 0.0486 - val_loss: 0.0657 - 85ms/epoch - 21ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 0s - loss: 0.0487 - val_loss: 0.0659 - 84ms/epoch - 21ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 0s - loss: 0.0484 - val_loss: 0.0652 - 85ms/epoch - 21ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 0s - loss: 0.0481 - val_loss: 0.0649 - 87ms/epoch - 22ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 0s - loss: 0.0480 - val_loss: 0.0642 - 90ms/epoch - 22ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 0s - loss: 0.0475 - val_loss: 0.0650 - 125ms/epoch - 31ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 0s - loss: 0.0476 - val_loss: 0.0648 - 86ms/epoch - 22ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 0s - loss: 0.0472 - val_loss: 0.0636 - 86ms/epoch - 21ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 0s - loss: 0.0468 - val_loss: 0.0629 - 84ms/epoch - 21ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 0s - loss: 0.0471 - val_loss: 0.0665 - 79ms/epoch - 20ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 0s - loss: 0.0492 - val_loss: 0.0650 - 81ms/epoch - 20ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 0s - loss: 0.0480 - val_loss: 0.0640 - 83ms/epoch - 21ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 0s - loss: 0.0465 - val_loss: 0.0618 - 87ms/epoch - 22ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 0s - loss: 0.0461 - val_loss: 0.0630 - 81ms/epoch - 20ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 0s - loss: 0.0463 - val_loss: 0.0653 - 89ms/epoch - 22ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 0s - loss: 0.0475 - val_loss: 0.0643 - 84ms/epoch - 21ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 0s - loss: 0.0460 - val_loss: 0.0621 - 96ms/epoch - 24ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 0s - loss: 0.0458 - val_loss: 0.0619 - 82ms/epoch - 20ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 0s - loss: 0.0459 - val_loss: 0.0660 - 87ms/epoch - 22ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 0s - loss: 0.0480 - val_loss: 0.0635 - 82ms/epoch - 20ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 0s - loss: 0.0458 - val_loss: 0.0631 - 83ms/epoch - 21ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 0s - loss: 0.0462 - val_loss: 0.0611 - 84ms/epoch - 21ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 0s - loss: 0.0449 - val_loss: 0.0632 - 81ms/epoch - 20ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 0s - loss: 0.0457 - val_loss: 0.0618 - 83ms/epoch - 21ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 0s - loss: 0.0437 - val_loss: 0.0601 - 87ms/epoch - 22ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 0s - loss: 0.0433 - val_loss: 0.0621 - 82ms/epoch - 20ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 0s - loss: 0.0444 - val_loss: 0.0616 - 84ms/epoch - 21ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 0s - loss: 0.0441 - val_loss: 0.0608 - 84ms/epoch - 21ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 0s - loss: 0.0426 - val_loss: 0.0599 - 82ms/epoch - 21ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 0s - loss: 0.0426 - val_loss: 0.0612 - 81ms/epoch - 20ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 0s - loss: 0.0429 - val_loss: 0.0607 - 87ms/epoch - 22ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 0s - loss: 0.0427 - val_loss: 0.0603 - 83ms/epoch - 21ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 0s - loss: 0.0426 - val_loss: 0.0590 - 90ms/epoch - 23ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 0s - loss: 0.0418 - val_loss: 0.0584 - 90ms/epoch - 23ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 0s - loss: 0.0429 - val_loss: 0.0601 - 87ms/epoch - 22ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 0s - loss: 0.0425 - val_loss: 0.0664 - 82ms/epoch - 21ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 0s - loss: 0.0496 - val_loss: 0.0630 - 81ms/epoch - 20ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 0s - loss: 0.0437 - val_loss: 0.0577 - 88ms/epoch - 22ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 0s - loss: 0.0425 - val_loss: 0.0584 - 83ms/epoch - 21ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 0s - loss: 0.0416 - val_loss: 0.0589 - 85ms/epoch - 21ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 0s - loss: 0.0415 - val_loss: 0.0586 - 92ms/epoch - 23ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 0s - loss: 0.0410 - val_loss: 0.0575 - 89ms/epoch - 22ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 0s - loss: 0.0419 - val_loss: 0.0593 - 83ms/epoch - 21ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 0s - loss: 0.0416 - val_loss: 0.0619 - 80ms/epoch - 20ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 0s - loss: 0.0442 - val_loss: 0.0604 - 85ms/epoch - 21ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 0s - loss: 0.0423 - val_loss: 0.0573 - 82ms/epoch - 20ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 0s - loss: 0.0409 - val_loss: 0.0575 - 82ms/epoch - 20ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 0s - loss: 0.0405 - val_loss: 0.0578 - 83ms/epoch - 21ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 0s - loss: 0.0403 - val_loss: 0.0574 - 82ms/epoch - 20ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 0s - loss: 0.0400 - val_loss: 0.0567 - 86ms/epoch - 21ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 0s - loss: 0.0401 - val_loss: 0.0571 - 83ms/epoch - 21ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 0s - loss: 0.0401 - val_loss: 0.0581 - 85ms/epoch - 21ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 0s - loss: 0.0406 - val_loss: 0.0577 - 84ms/epoch - 21ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 0s - loss: 0.0405 - val_loss: 0.0565 - 97ms/epoch - 24ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 0s - loss: 0.0429 - val_loss: 0.0576 - 77ms/epoch - 19ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 0s - loss: 0.0407 - val_loss: 0.0578 - 81ms/epoch - 20ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 0s - loss: 0.0410 - val_loss: 0.0586 - 87ms/epoch - 22ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 0s - loss: 0.0412 - val_loss: 0.0560 - 87ms/epoch - 22ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 0s - loss: 0.0401 - val_loss: 0.0573 - 82ms/epoch - 21ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 0s - loss: 0.0400 - val_loss: 0.0580 - 80ms/epoch - 20ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 0s - loss: 0.0406 - val_loss: 0.0575 - 94ms/epoch - 24ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 0s - loss: 0.0425 - val_loss: 0.0564 - 84ms/epoch - 21ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 0s - loss: 0.0406 - val_loss: 0.0579 - 87ms/epoch - 22ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 0s - loss: 0.0414 - val_loss: 0.0606 - 94ms/epoch - 23ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 0s - loss: 0.0417 - val_loss: 0.0582 - 85ms/epoch - 21ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 0s - loss: 0.0397 - val_loss: 0.0558 - 86ms/epoch - 21ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 0s - loss: 0.0391 - val_loss: 0.0551 - 88ms/epoch - 22ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 0s - loss: 0.0400 - val_loss: 0.0563 - 88ms/epoch - 22ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 0s - loss: 0.0393 - val_loss: 0.0564 - 85ms/epoch - 21ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 0s - loss: 0.0395 - val_loss: 0.0556 - 80ms/epoch - 20ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 0s - loss: 0.0399 - val_loss: 0.0549 - 86ms/epoch - 22ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 0s - loss: 0.0396 - val_loss: 0.0581 - 83ms/epoch - 21ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 0s - loss: 0.0418 - val_loss: 0.0604 - 84ms/epoch - 21ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 0s - loss: 0.0410 - val_loss: 0.0575 - 81ms/epoch - 20ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 0s - loss: 0.0392 - val_loss: 0.0546 - 88ms/epoch - 22ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 0s - loss: 0.0389 - val_loss: 0.0550 - 87ms/epoch - 22ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 0s - loss: 0.0413 - val_loss: 0.0582 - 89ms/epoch - 22ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 0s - loss: 0.0411 - val_loss: 0.0592 - 86ms/epoch - 22ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 0s - loss: 0.0400 - val_loss: 0.0556 - 89ms/epoch - 22ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 0s - loss: 0.0382 - val_loss: 0.0542 - 89ms/epoch - 22ms/step\n",
            "Epoch 166/1000\n",
            "4/4 - 0s - loss: 0.0384 - val_loss: 0.0547 - 81ms/epoch - 20ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 0s - loss: 0.0383 - val_loss: 0.0557 - 79ms/epoch - 20ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 0s - loss: 0.0390 - val_loss: 0.0555 - 91ms/epoch - 23ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 0s - loss: 0.0395 - val_loss: 0.0539 - 95ms/epoch - 24ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 0s - loss: 0.0389 - val_loss: 0.0565 - 85ms/epoch - 21ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 0s - loss: 0.0404 - val_loss: 0.0597 - 87ms/epoch - 22ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 0s - loss: 0.0413 - val_loss: 0.0596 - 78ms/epoch - 20ms/step\n",
            "Epoch 173/1000\n",
            "4/4 - 0s - loss: 0.0411 - val_loss: 0.0569 - 88ms/epoch - 22ms/step\n",
            "Epoch 174/1000\n",
            "4/4 - 0s - loss: 0.0393 - val_loss: 0.0547 - 84ms/epoch - 21ms/step\n",
            "Epoch 175/1000\n",
            "4/4 - 0s - loss: 0.0379 - val_loss: 0.0543 - 84ms/epoch - 21ms/step\n",
            "Epoch 176/1000\n",
            "4/4 - 0s - loss: 0.0377 - val_loss: 0.0538 - 86ms/epoch - 22ms/step\n",
            "Epoch 177/1000\n",
            "4/4 - 0s - loss: 0.0381 - val_loss: 0.0559 - 82ms/epoch - 20ms/step\n",
            "Epoch 178/1000\n",
            "4/4 - 0s - loss: 0.0388 - val_loss: 0.0559 - 80ms/epoch - 20ms/step\n",
            "Epoch 179/1000\n",
            "4/4 - 0s - loss: 0.0378 - val_loss: 0.0537 - 84ms/epoch - 21ms/step\n",
            "Epoch 180/1000\n",
            "4/4 - 0s - loss: 0.0378 - val_loss: 0.0548 - 89ms/epoch - 22ms/step\n",
            "Epoch 181/1000\n",
            "4/4 - 0s - loss: 0.0376 - val_loss: 0.0547 - 77ms/epoch - 19ms/step\n",
            "Epoch 182/1000\n",
            "4/4 - 0s - loss: 0.0373 - val_loss: 0.0541 - 89ms/epoch - 22ms/step\n",
            "Epoch 183/1000\n",
            "4/4 - 0s - loss: 0.0390 - val_loss: 0.0545 - 84ms/epoch - 21ms/step\n",
            "Epoch 184/1000\n",
            "4/4 - 0s - loss: 0.0377 - val_loss: 0.0559 - 87ms/epoch - 22ms/step\n",
            "Epoch 185/1000\n",
            "4/4 - 0s - loss: 0.0387 - val_loss: 0.0563 - 91ms/epoch - 23ms/step\n",
            "Epoch 186/1000\n",
            "4/4 - 0s - loss: 0.0408 - val_loss: 0.0552 - 85ms/epoch - 21ms/step\n",
            "Epoch 187/1000\n",
            "4/4 - 0s - loss: 0.0383 - val_loss: 0.0558 - 82ms/epoch - 20ms/step\n",
            "Epoch 188/1000\n",
            "4/4 - 0s - loss: 0.0392 - val_loss: 0.0580 - 82ms/epoch - 20ms/step\n",
            "Epoch 189/1000\n",
            "4/4 - 0s - loss: 0.0399 - val_loss: 0.0568 - 86ms/epoch - 22ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DetuxaYg7V9x"
      },
      "source": [
        "## Predictions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUI-z2ULSR2T"
      },
      "source": [
        "# make a prediction\n",
        "yhat = model.predict(test_X)\n",
        "test_X = test_X.reshape((test_X.shape[0], n_days*n_features))\n",
        "# invert scaling for forecast\n",
        "inv_yhat = concatenate((yhat, test_X[:, -6:]), axis=1)\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat = inv_yhat[:,0]\n",
        "# invert scaling for actual\n",
        "test_y = test_y.reshape((len(test_y), 1))\n",
        "inv_y = concatenate((test_y, test_X[:, -6:]), axis=1)\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y = inv_y[:,0]\n",
        "# calculate RMSE\n",
        "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.3f' % rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUBP-sQGNNzg"
      },
      "source": [
        "# make a prediction using 2020 (not used for training or validation, and has different dynamics due to covid)\n",
        "# adding back the data from 2020\n",
        "Moggio = table.loc[table.loc[:,\"NameStation\"]==\"Moggio\",:]\n",
        "Moggio = Moggio.loc[:,[\"Date\",\"Ammonia\",\"PM10\",\"PM25\",\"Wind_speed\",\"Wind_direction\",\"Temperature\",\"Rainfall\"]]\n",
        "Moggio = Moggio.dropna(how=\"any\")\n",
        "Moggio = Moggio.reset_index()\n",
        "#scaling and creating the new testing data\n",
        "values = Moggio.iloc[:,2:].values\n",
        "# ensure all data is float\n",
        "values = values.astype('float32')\n",
        "# normalize features\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(values)\n",
        "# frame as supervised learning\n",
        "n_days = 5\n",
        "reframed = series_to_supervised(scaled, n_days, 1) # info of the past 5 days to determine next (1) day\n",
        "# drop columns we don't want to predict (we therefore keep Ammonia)\n",
        "reframed.drop(reframed.columns[[36,37,38,39,40,41]], axis=1, inplace=True)\n",
        "# split into train and test sets\n",
        "values = reframed.values\n",
        "n_features = 7 # number of variables, including the one to be predicted\n",
        "n_train_days = 365 # we train using only the first year\n",
        "train = values[:n_train_days, :]\n",
        "test = values[n_train_days:, :] # we test using all successive years \n",
        "# split into input and outputs\n",
        "n_obs = n_days * n_features\n",
        "train_X, train_y = train[:, :n_obs], train[:, -1]\n",
        "test_X, test_y = test[:, :n_obs], test[:, -1]\n",
        "print(train_X.shape, len(train_X), train_y.shape)\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], n_days, n_features))\n",
        "test_X = test_X.reshape((test_X.shape[0], n_days, n_features))\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAiSyZq1L95c"
      },
      "source": [
        "# predicting: make a prediction using 2019 and 2020 (not used for training or validation, and has different dynamics due to covid)\n",
        "yhat = model.predict(test_X)\n",
        "test_X = test_X.reshape((test_X.shape[0], n_days*n_features))\n",
        "# invert scaling for forecast\n",
        "inv_yhat = concatenate((yhat, test_X[:, -6:]), axis=1)\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat = inv_yhat[:,0]\n",
        "# invert scaling for actual\n",
        "test_y = test_y.reshape((len(test_y), 1))\n",
        "inv_y = concatenate((test_y, test_X[:, -6:]), axis=1)\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y = inv_y[:,0]\n",
        "# calculate RMSE\n",
        "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.3f' % rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhNcUjYz7Z5J"
      },
      "source": [
        "#### Prediciton plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgvSi2LHmWWP"
      },
      "source": [
        "pyplot.plot(inv_yhat, label = 'Prediction')\n",
        "pyplot.plot(inv_y, label = 'Real')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q0ykqpFDURq"
      },
      "source": [
        "# Modeling with hyperparamenter search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDxlDo3dDfWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b593f2-c26e-4891-a5a3-cd0354776182"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 98 kB 5.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_ykkd6DDYms"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_tuner as kt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqJaEiI8OiX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6361bc54-f906-4b6e-9f16-83c7d09e8b54"
      },
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaRj2wPcDp6h"
      },
      "source": [
        "def model_builder(hp):\n",
        "  # design network\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(units = hp_units,return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "  for i in range(hp.Int('layers',1,3)):\n",
        "   model.add(LSTM(units = hp_units, return_sequences=True))\n",
        "  model.add(LSTM(units = hp_units, return_sequences=False))\n",
        "  model.add(Dense(1))\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  model.compile(loss='mae', optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y8l3BlbLFn4"
      },
      "source": [
        "def model_builder(hp):\n",
        "  # design network\n",
        "  hp_units = hp.Int('units', min_value=10, max_value=100, step=25)\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(units = hp_units,return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "  for i in range(hp.Int('layers',0,1)):\n",
        "   model.add(LSTM(units = hp_units, return_sequences=True))\n",
        "  model.add(LSTM(units = hp_units, return_sequences=False))\n",
        "  model.add(Dense(1))\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  model.compile(loss='mae', optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHv2TK6MGMF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7990799b-c231-46de-92c1-f2aa85b3b3b4"
      },
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    model_builder,\n",
        "    objective='val_loss',\n",
        "    max_trials=10,\n",
        "    executions_per_trial =3,\n",
        "    directory = 'dir',\n",
        "    project_name = 'namee')\n",
        "tuner.search_space_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 3\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 100, 'step': 25, 'sampling': None}\n",
            "layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 0, 'max_value': 1, 'step': 1, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-Jjf4glG9h4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d747d4a8-e1f9-4780-cb6f-ba7c4c8058fc"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss',patience=10)\n",
        "tuner.search(train_X, train_y, epochs=100, batch_size=100, validation_data=(test_X, test_y),shuffle=False, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 11 Complete [00h 01m 12s]\n",
            "val_loss: 0.0934639647603035\n",
            "\n",
            "Best val_loss So Far: 0.05329474558432897\n",
            "Total elapsed time: 00h 09m 48s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVo9l3foLH15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5fda3d-96f4-41af-d516-6f30c1c5b5d6"
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in dir/namee\n",
            "Showing 10 best trials\n",
            "Objective(name='val_loss', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 85\n",
            "layers: 0\n",
            "learning_rate: 0.001\n",
            "Score: 0.05329474558432897\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 60\n",
            "layers: 0\n",
            "learning_rate: 0.001\n",
            "Score: 0.05329849198460579\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 85\n",
            "layers: 0\n",
            "learning_rate: 0.01\n",
            "Score: 0.056007577727238335\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 60\n",
            "layers: 1\n",
            "learning_rate: 0.001\n",
            "Score: 0.057568988452355065\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 35\n",
            "layers: 0\n",
            "learning_rate: 0.001\n",
            "Score: 0.05804020414749781\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 10\n",
            "layers: 1\n",
            "learning_rate: 0.001\n",
            "Score: 0.08332389841477077\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 60\n",
            "layers: 0\n",
            "learning_rate: 0.0001\n",
            "Score: 0.08504390716552734\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 85\n",
            "layers: 1\n",
            "learning_rate: 0.0001\n",
            "Score: 0.09046338746945064\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 60\n",
            "layers: 1\n",
            "learning_rate: 0.0001\n",
            "Score: 0.0934639647603035\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 35\n",
            "layers: 1\n",
            "learning_rate: 0.0001\n",
            "Score: 0.11205451438824336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm9281SoM7Hy"
      },
      "source": [
        "### Hyperband"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMZiMT1KAO6"
      },
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_loss',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6r3Ft2PIahk"
      },
      "source": [
        "tuner.search(train_X, train_y, epochs=1000, batch_size=72, validation_data=(test_X, test_y),shuffle=False, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}